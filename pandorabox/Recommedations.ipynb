{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "install = pd.read_csv('./Indus_OS_Participants_Data/app_installs.csv')\n",
    "install['uid'] = install['uid'].astype(str)\n",
    "install['item_id'] = install['item_id'].astype(str)\n",
    "\n",
    "validation = pd.read_csv('./Indus_OS_Participants_Data/validation_data.csv')\n",
    "validation['uid'] = validation['uid'].astype(str)\n",
    "\n",
    "meta = pd.read_csv('./Indus_OS_Participants_Data/app_metadata.csv')\n",
    "meta['item_id'] = meta['item_id'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Popular Apps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = pd.read_csv(\"./Indus_OS_Participants_Data/app_installs.csv\")\n",
    "items = fp.item_id.unique()\n",
    "dic = {}\n",
    "for i in items:\n",
    "    k = fp[fp['item_id'] == i]\n",
    "    dic[i] = [\n",
    "        k[k['status'] == 'installed'].shape[0],k[k['status'] == 'uninstalled'].shape[0]\n",
    "    ]\n",
    "pop = pd.DataFrame({'id':dic.keys(),'instals':[i[0] for i in dic.values()],'uinstals':[i[1] for i in dic.values()], })\n",
    "\n",
    "\n",
    "pop['instals'] = pop['instals'] +1\n",
    "pop['uinstals'] = pop['uinstals'] +1\n",
    "pop.head()\n",
    "pop.to_csv('./cont_matrix/popp.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pops = pd.read_csv('./cont_matrix/popp.csv')\n",
    "pops['id'] = pops['id'].astype(str)\n",
    "ff = dict(pops[['id','score']].values)\n",
    "def get_fg(x):\n",
    "    try:\n",
    "        return ff[x]\n",
    "    except Exception as e:\n",
    "        return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta['score'] = meta['item_id'].apply(lambda x: get_fg(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff = list(set(validation['uid'].astype(str)))\n",
    "install = install[install['uid'].astype(str).isin(ff)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len((set(install['item_id'].astype(str))).difference(set(meta['item_id'].astype(str)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# creating user's profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install['install_date'] = pd.to_datetime(install['install_date'],infer_datetime_format=True)\n",
    "df1 = install.sort_values('install_date').groupby('uid',sort=False)['item_id'].apply(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = dict(meta[['item_id','category']].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_cat(x):\n",
    "    ff =  []\n",
    "    for xi in x:\n",
    "        try:\n",
    "            ff.append(categories[xi])\n",
    "        except Exception as e:\n",
    "            ff.append(xi)\n",
    "    return ff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['categories'] = df1['item_id'].apply(lambda x: retrieve_cat(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# last 8 categories\n",
    "df1['search_cat'] = df1['categories'].apply(lambda x : x[-8:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mode\n",
    "def retrieve_most(xi):\n",
    "    try:\n",
    "        x1  = mode(xi)\n",
    "        if len(xi) < 2:\n",
    "            return xi\n",
    "        xi = [i for i in xi if i!=x1]\n",
    "        x2 = mode(xi)\n",
    "        return [x1,x2]\n",
    "    except Exception as e:\n",
    "        return xi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 most watched and 5 recent\n",
    "df1['most_used'] = df1['categories'].apply(lambda x: retrieve_most(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['search_category'] = df1['search_cat'] + df1['most_used']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['search_category'] = df1['search_category'].apply(lambda x: list(set(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1[['uid','search_category','item_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Most Similar Apps based on popularity, recent and most used app category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import nltk\n",
    "from bs4 import BeautifulSoup\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U000024C2-\\U0001F251\"\n",
    "                               u\"\\U0001f926-\\U0001f937\"\n",
    "                               u\"\\U00010000-\\U0010ffff\"\n",
    "                               u\"\\u2640-\\u2642\"\n",
    "                               u\"\\u2600-\\u2B55\"\n",
    "                               u\"\\u200d\"\n",
    "                               u\"\\u23cf\"\n",
    "                               u\"\\u23e9\"\n",
    "                               u\"\\u231a\"\n",
    "                               u\"\\ufe0f\"  # dingbats\n",
    "                               u\"\\u3030\"\n",
    "                               \"]+\", flags=re.UNICODE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text = re.sub(r'https\\S','',text)\n",
    "    text = text.lower()\n",
    "    text = re.sub(\"\\d+\", \" \", text)\n",
    "    text = re.sub(r'<br>','',text)\n",
    "    text = re.sub(r'&amp','',text)\n",
    "    text = re.sub(r'[:;,-?]',' ',text)\n",
    "    text = re.sub(r'\\n',' ',text)\n",
    "    text = re.sub('\\(.*?\\)','',text)\n",
    "    text = emoji_pattern.sub(r'', text)\n",
    "    \n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cosine_similarity(text1, text2):\n",
    "    \n",
    "    # stores text in a list\n",
    "    list_text = [text1, text2]\n",
    "    \n",
    "    # converts text into vectors with the TF-IDF \n",
    "    vectorizer = TfidfVectorizer(stop_words='english')\n",
    "    vectorizer.fit_transform(list_text)\n",
    "    tfidf_text1, tfidf_text2 = vectorizer.transform([list_text[0]]), vectorizer.transform([list_text[1]])\n",
    "    \n",
    "    # computes the cosine similarity\n",
    "    cs_score = cosine_similarity(tfidf_text1, tfidf_text2)\n",
    "    \n",
    "    return np.round(cs_score[0][0],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cout = 0\n",
    "def compare_seneteces(c):\n",
    "    global cout\n",
    "    cout +=1\n",
    "    print(cout)\n",
    "    # c = df1.iloc[0]\n",
    "    try:\n",
    "        items = meta['item_id'].unique()\n",
    "        used = list(c['item_id'])\n",
    "        recent = used[-8:]\n",
    "        recentdesc = meta[meta['item_id'].isin(recent)]['description']\n",
    "        search_cat = c['search_category']\n",
    "        \n",
    "        # meta[(meta['item_id'].isin(left)) & (meta['category'].isin(search_cat))]\n",
    "        retrieved =  meta[~(meta['item_id'].isin(used))]\n",
    "        retrieved = retrieved[retrieved['category'].isin(search_cat)][:30]\n",
    "        \n",
    "        recent = recentdesc.to_string()\n",
    "        sen1 = preprocess(recent)\n",
    "        hash_map = {\n",
    "        }\n",
    "        for i in range(len(retrieved)):\n",
    "        \n",
    "            k = retrieved.iloc[i]\n",
    "            sen2 = preprocess(k['description'])\n",
    "            hash_map[k['item_id']] = compute_cosine_similarity(sen1,sen2)\n",
    "        hash_map = dict(sorted(hash_map.items(), key=lambda item: item[1],reverse=True))\n",
    "        return list(hash_map.keys())[:4]\n",
    "    except Exception as e:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['recomms']  = df1.apply(lambda x: compare_seneteces(x),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 =  df1.drop(['search_category','item_id'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(set(validation['uid'])))\n",
    "print(len(set(df1['uid']).intersection(set(validation['uid']))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.explode('recomms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv('sub1_1.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
