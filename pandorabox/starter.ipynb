{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f93de1de-bd70-42ff-b9eb-914bc72c5676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install jovian --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d61abc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jovian in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (0.2.41)\r\n",
      "Requirement already satisfied: click in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from jovian) (8.1.3)\r\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from jovian) (2.28.1)\r\n",
      "Requirement already satisfied: uuid in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from jovian) (1.30)\r\n",
      "Requirement already satisfied: pyyaml in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from jovian) (6.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->jovian) (2022.6.15)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->jovian) (1.26.11)\r\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->jovian) (2.1.0)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->jovian) (3.3)\r\n"
     ]
    }
   ],
   "source": [
    "!pip3 install jovian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e826efb7-7303-4495-942f-69a7d4c21e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#library imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy import sparse\n",
    "import sys\n",
    "import jovian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdce616",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "981a9025-4b6d-4063-bc59-494fb5d3a37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_set = pd.read_csv('actual_set.csv')\n",
    "app_installs = pd.read_csv('app_installs.csv')\n",
    "app_metadata = pd.read_csv('app_metadata.csv')\n",
    "app_usage = pd.read_csv('app_usage.csv')\n",
    "user_metadata = pd.read_csv('user_metadata.csv')\n",
    "validation_data = pd.read_csv('validation_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdfb1f8e-eb4c-47f5-8faf-f82fa85fabbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>device</th>\n",
       "      <th>device_category</th>\n",
       "      <th>state</th>\n",
       "      <th>city</th>\n",
       "      <th>network_type</th>\n",
       "      <th>user_lang</th>\n",
       "      <th>space_available</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>94698</td>\n",
       "      <td>SM-M215F</td>\n",
       "      <td>Mid</td>\n",
       "      <td>Assam</td>\n",
       "      <td>Dibrugarh</td>\n",
       "      <td>4G</td>\n",
       "      <td>en-US</td>\n",
       "      <td>94.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>257076</td>\n",
       "      <td>SM-J400F</td>\n",
       "      <td>Mass</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>Siliguri</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>283805</td>\n",
       "      <td>SM-J415F</td>\n",
       "      <td>Mass</td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>Deogarh</td>\n",
       "      <td>wifi</td>\n",
       "      <td>en-US</td>\n",
       "      <td>11.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>248262</td>\n",
       "      <td>SM-A336E</td>\n",
       "      <td>High</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>Ahmedabad</td>\n",
       "      <td>4G</td>\n",
       "      <td>en-US</td>\n",
       "      <td>91.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>283806</td>\n",
       "      <td>SM-M205F</td>\n",
       "      <td>Mid</td>\n",
       "      <td>National Capital Territory of Delhi</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>4G</td>\n",
       "      <td>en-US</td>\n",
       "      <td>42.62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      uid    device device_category                                state  \\\n",
       "0   94698  SM-M215F             Mid                                Assam   \n",
       "1  257076  SM-J400F            Mass                          West Bengal   \n",
       "2  283805  SM-J415F            Mass                            Jharkhand   \n",
       "3  248262  SM-A336E            High                              Gujarat   \n",
       "4  283806  SM-M205F             Mid  National Capital Territory of Delhi   \n",
       "\n",
       "        city network_type user_lang  space_available  \n",
       "0  Dibrugarh           4G     en-US            94.32  \n",
       "1   Siliguri          NaN       NaN              NaN  \n",
       "2    Deogarh         wifi     en-US            11.45  \n",
       "3  Ahmedabad           4G     en-US            91.20  \n",
       "4      Delhi           4G     en-US            42.62  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b20326ba-9071-4a06-9a63-e0d2166d92dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "app_usage = app_usage.drop('app_use_date', axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53f3abef-1a19-4601-848b-5e10ab7bb5ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>item_id</th>\n",
       "      <th>time_spent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>185459</td>\n",
       "      <td>601235</td>\n",
       "      <td>2180211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>164721</td>\n",
       "      <td>601235</td>\n",
       "      <td>4850939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22949</td>\n",
       "      <td>601235</td>\n",
       "      <td>1026713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1773</td>\n",
       "      <td>601235</td>\n",
       "      <td>419773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12539</td>\n",
       "      <td>601235</td>\n",
       "      <td>1609444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      uid  item_id  time_spent\n",
       "0  185459   601235     2180211\n",
       "1  164721   601235     4850939\n",
       "2   22949   601235     1026713\n",
       "3    1773   601235      419773\n",
       "4   12539   601235     1609444"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app_usage.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d8b0f59-057d-46f1-bf92-926f2c7a6886",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>item_id</th>\n",
       "      <th>time_spent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>185459</td>\n",
       "      <td>601235</td>\n",
       "      <td>36.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>164721</td>\n",
       "      <td>601235</td>\n",
       "      <td>80.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22949</td>\n",
       "      <td>601235</td>\n",
       "      <td>17.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1773</td>\n",
       "      <td>601235</td>\n",
       "      <td>7.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12539</td>\n",
       "      <td>601235</td>\n",
       "      <td>26.82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      uid  item_id  time_spent\n",
       "0  185459   601235       36.34\n",
       "1  164721   601235       80.85\n",
       "2   22949   601235       17.11\n",
       "3    1773   601235        7.00\n",
       "4   12539   601235       26.82"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Filtering users who spent time atleast more than 10 seconds\n",
    "app_usage = app_usage.loc[app_usage['time_spent'] > 10000] \n",
    "\n",
    "#Converting milliseconds to minutes\n",
    "app_usage['time_spent'] = app_usage['time_spent'].div(60000).round(2)\n",
    "\n",
    "app_usage.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7aaf0dfe-cb00-4840-9538-193574195952",
   "metadata": {},
   "outputs": [],
   "source": [
    "app_usage.rename(columns = {'time_spent':'rating'}, inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ec2567e-acfb-4b4d-8194-e161ed2f5af7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>185459</td>\n",
       "      <td>601235</td>\n",
       "      <td>36.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>164721</td>\n",
       "      <td>601235</td>\n",
       "      <td>80.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22949</td>\n",
       "      <td>601235</td>\n",
       "      <td>17.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1773</td>\n",
       "      <td>601235</td>\n",
       "      <td>7.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12539</td>\n",
       "      <td>601235</td>\n",
       "      <td>26.82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      uid  item_id  rating\n",
       "0  185459   601235   36.34\n",
       "1  164721   601235   80.85\n",
       "2   22949   601235   17.11\n",
       "3    1773   601235    7.00\n",
       "4   12539   601235   26.82"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app_usage.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8326b15-5ade-4170-8250-3c7e885030bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "uid        0\n",
       "item_id    0\n",
       "rating     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app_usage.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a92000b-2f63-40d8-96b8-a048489dd9d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({36.34: 285,\n",
       "         80.85: 109,\n",
       "         17.11: 749,\n",
       "         7.0: 1863,\n",
       "         26.82: 441,\n",
       "         14.88: 874,\n",
       "         25.61: 467,\n",
       "         6.85: 1872,\n",
       "         36.51: 277,\n",
       "         0.89: 9987,\n",
       "         1.74: 6374,\n",
       "         1.23: 8285,\n",
       "         0.96: 9630,\n",
       "         0.34: 16738,\n",
       "         3.33: 3790,\n",
       "         6.42: 2108,\n",
       "         0.18: 24403,\n",
       "         7.19: 1753,\n",
       "         0.58: 13389,\n",
       "         0.65: 12525,\n",
       "         1.0: 9434,\n",
       "         0.54: 14657,\n",
       "         0.99: 9502,\n",
       "         1.35: 7702,\n",
       "         12.02: 1096,\n",
       "         0.51: 14319,\n",
       "         7.14: 1915,\n",
       "         10.98: 1230,\n",
       "         2.72: 4449,\n",
       "         17.62: 787,\n",
       "         5.54: 2320,\n",
       "         2.34: 5227,\n",
       "         12.89: 1056,\n",
       "         0.42: 14971,\n",
       "         0.93: 9891,\n",
       "         2.35: 5127,\n",
       "         52.42: 198,\n",
       "         1.03: 9461,\n",
       "         14.04: 944,\n",
       "         0.2: 22879,\n",
       "         3.9: 3214,\n",
       "         8.49: 1514,\n",
       "         1.63: 6750,\n",
       "         5.72: 2272,\n",
       "         1.28: 8037,\n",
       "         2.16: 5450,\n",
       "         5.51: 2277,\n",
       "         57.64: 154,\n",
       "         0.79: 10832,\n",
       "         1.18: 8493,\n",
       "         1.8: 6209,\n",
       "         1.31: 7926,\n",
       "         0.64: 12606,\n",
       "         0.55: 14385,\n",
       "         12.08: 1099,\n",
       "         36.77: 299,\n",
       "         6.15: 2041,\n",
       "         2.86: 4439,\n",
       "         12.34: 1048,\n",
       "         9.04: 1459,\n",
       "         4.84: 2698,\n",
       "         1.09: 8916,\n",
       "         14.18: 913,\n",
       "         15.33: 910,\n",
       "         12.82: 978,\n",
       "         2.96: 4229,\n",
       "         0.39: 15575,\n",
       "         1.57: 6806,\n",
       "         32.21: 362,\n",
       "         36.91: 303,\n",
       "         0.37: 16096,\n",
       "         18.72: 677,\n",
       "         14.92: 877,\n",
       "         5.39: 2431,\n",
       "         35.23: 313,\n",
       "         3.5: 3643,\n",
       "         9.44: 1452,\n",
       "         10.29: 1297,\n",
       "         3.66: 3540,\n",
       "         0.27: 19098,\n",
       "         10.52: 1256,\n",
       "         2.42: 4953,\n",
       "         6.7: 1963,\n",
       "         6.88: 1833,\n",
       "         0.38: 15811,\n",
       "         2.11: 5568,\n",
       "         2.85: 4299,\n",
       "         0.66: 12174,\n",
       "         7.79: 1663,\n",
       "         17.67: 747,\n",
       "         18.78: 685,\n",
       "         34.16: 294,\n",
       "         16.91: 708,\n",
       "         33.2: 334,\n",
       "         1.15: 8581,\n",
       "         77.15: 104,\n",
       "         2.55: 4792,\n",
       "         1.37: 7660,\n",
       "         2.17: 5377,\n",
       "         6.56: 2019,\n",
       "         1.46: 7246,\n",
       "         5.21: 2545,\n",
       "         0.98: 9519,\n",
       "         4.35: 2971,\n",
       "         19.96: 635,\n",
       "         1.33: 7711,\n",
       "         4.7: 2866,\n",
       "         7.22: 1868,\n",
       "         5.05: 2642,\n",
       "         14.75: 840,\n",
       "         12.54: 1083,\n",
       "         51.6: 180,\n",
       "         51.27: 170,\n",
       "         3.6: 3492,\n",
       "         158.02: 17,\n",
       "         124.8: 36,\n",
       "         245.39: 8,\n",
       "         123.64: 33,\n",
       "         125.01: 34,\n",
       "         176.46: 19,\n",
       "         122.36: 48,\n",
       "         153.57: 28,\n",
       "         188.06: 11,\n",
       "         57.88: 154,\n",
       "         8.36: 1604,\n",
       "         44.34: 217,\n",
       "         10.1: 1343,\n",
       "         2.29: 5194,\n",
       "         1.42: 7453,\n",
       "         1.94: 5913,\n",
       "         1.47: 7388,\n",
       "         1.89: 6070,\n",
       "         5.5: 2263,\n",
       "         12.14: 1080,\n",
       "         3.64: 3495,\n",
       "         2.77: 4395,\n",
       "         17.98: 708,\n",
       "         1.77: 6267,\n",
       "         0.43: 14856,\n",
       "         8.88: 1504,\n",
       "         7.46: 1748,\n",
       "         7.86: 1687,\n",
       "         0.52: 14141,\n",
       "         8.57: 1504,\n",
       "         8.78: 1508,\n",
       "         0.56: 13958,\n",
       "         10.83: 1221,\n",
       "         29.19: 420,\n",
       "         33.1: 375,\n",
       "         8.75: 1516,\n",
       "         14.06: 853,\n",
       "         30.51: 377,\n",
       "         54.92: 168,\n",
       "         21.38: 581,\n",
       "         3.24: 3809,\n",
       "         3.95: 3121,\n",
       "         2.94: 4257,\n",
       "         1.9: 6100,\n",
       "         4.85: 2598,\n",
       "         2.25: 5400,\n",
       "         0.47: 13860,\n",
       "         0.45: 14232,\n",
       "         0.69: 11868,\n",
       "         0.91: 10031,\n",
       "         2.48: 4895,\n",
       "         7.2: 1843,\n",
       "         13.19: 925,\n",
       "         2.95: 4148,\n",
       "         14.11: 952,\n",
       "         9.52: 1425,\n",
       "         34.59: 300,\n",
       "         197.76: 11,\n",
       "         2.21: 5276,\n",
       "         2.62: 4737,\n",
       "         3.18: 3967,\n",
       "         2.01: 5937,\n",
       "         0.62: 12894,\n",
       "         0.53: 14749,\n",
       "         0.49: 13671,\n",
       "         2.46: 5022,\n",
       "         3.98: 3208,\n",
       "         0.82: 10657,\n",
       "         4.02: 3102,\n",
       "         14.91: 869,\n",
       "         23.67: 507,\n",
       "         13.09: 949,\n",
       "         0.46: 14256,\n",
       "         2.59: 4705,\n",
       "         0.61: 12896,\n",
       "         2.27: 5316,\n",
       "         3.12: 4004,\n",
       "         1.14: 8753,\n",
       "         1.99: 5787,\n",
       "         5.09: 2574,\n",
       "         10.05: 1363,\n",
       "         2.37: 5158,\n",
       "         11.53: 1179,\n",
       "         0.36: 16428,\n",
       "         3.47: 3615,\n",
       "         10.53: 1260,\n",
       "         2.23: 5189,\n",
       "         1.16: 8577,\n",
       "         0.35: 16530,\n",
       "         1.48: 7215,\n",
       "         2.05: 5814,\n",
       "         0.67: 12105,\n",
       "         0.31: 17907,\n",
       "         1.19: 8462,\n",
       "         0.32: 17237,\n",
       "         0.59: 13509,\n",
       "         0.9: 9994,\n",
       "         0.44: 14665,\n",
       "         3.03: 4137,\n",
       "         4.32: 2964,\n",
       "         3.43: 3640,\n",
       "         0.29: 18453,\n",
       "         4.41: 2872,\n",
       "         2.06: 5662,\n",
       "         128.19: 29,\n",
       "         4.49: 2899,\n",
       "         0.71: 11537,\n",
       "         0.68: 12080,\n",
       "         1.88: 6184,\n",
       "         2.41: 4939,\n",
       "         0.78: 11020,\n",
       "         1.62: 6857,\n",
       "         0.22: 21475,\n",
       "         1.58: 7003,\n",
       "         0.41: 15144,\n",
       "         0.3: 18010,\n",
       "         0.73: 11360,\n",
       "         0.19: 23478,\n",
       "         0.84: 10729,\n",
       "         0.57: 13726,\n",
       "         1.81: 6331,\n",
       "         1.26: 8051,\n",
       "         2.74: 4636,\n",
       "         0.97: 9486,\n",
       "         1.01: 9454,\n",
       "         3.23: 3925,\n",
       "         0.72: 11522,\n",
       "         3.54: 3551,\n",
       "         1.05: 9162,\n",
       "         1.02: 9468,\n",
       "         0.85: 10500,\n",
       "         0.26: 19637,\n",
       "         0.77: 11081,\n",
       "         1.07: 9053,\n",
       "         4.45: 2986,\n",
       "         2.53: 4702,\n",
       "         1.45: 7311,\n",
       "         1.5: 7305,\n",
       "         0.4: 15301,\n",
       "         0.25: 20079,\n",
       "         0.24: 20504,\n",
       "         0.33: 17219,\n",
       "         1.06: 9102,\n",
       "         0.81: 10730,\n",
       "         3.06: 4129,\n",
       "         2.54: 4778,\n",
       "         0.94: 9661,\n",
       "         0.17: 21212,\n",
       "         3.84: 3349,\n",
       "         1.72: 6611,\n",
       "         0.21: 21939,\n",
       "         2.1: 5665,\n",
       "         14.42: 910,\n",
       "         1.98: 5891,\n",
       "         4.69: 2696,\n",
       "         1.08: 8889,\n",
       "         2.28: 5365,\n",
       "         1.49: 7344,\n",
       "         0.92: 9950,\n",
       "         4.6: 2902,\n",
       "         25.43: 505,\n",
       "         0.23: 21190,\n",
       "         0.5: 14533,\n",
       "         3.05: 4108,\n",
       "         1.79: 6257,\n",
       "         7.88: 1658,\n",
       "         10.9: 1196,\n",
       "         3.21: 3949,\n",
       "         4.89: 2613,\n",
       "         1.97: 5671,\n",
       "         8.24: 1641,\n",
       "         30.86: 386,\n",
       "         7.51: 1738,\n",
       "         50.04: 235,\n",
       "         11.66: 1053,\n",
       "         24.27: 500,\n",
       "         15.79: 841,\n",
       "         10.37: 1207,\n",
       "         19.14: 661,\n",
       "         7.4: 1840,\n",
       "         8.03: 1657,\n",
       "         8.56: 1485,\n",
       "         19.11: 631,\n",
       "         4.58: 2762,\n",
       "         3.8: 3362,\n",
       "         30.71: 386,\n",
       "         5.0: 2564,\n",
       "         24.03: 483,\n",
       "         13.39: 944,\n",
       "         11.17: 1192,\n",
       "         8.64: 1459,\n",
       "         240.73: 4,\n",
       "         20.66: 593,\n",
       "         86.03: 78,\n",
       "         34.53: 325,\n",
       "         5.13: 2570,\n",
       "         5.15: 2597,\n",
       "         2.82: 4485,\n",
       "         103.24: 53,\n",
       "         2.02: 5701,\n",
       "         40.87: 271,\n",
       "         15.29: 769,\n",
       "         33.11: 344,\n",
       "         52.74: 190,\n",
       "         14.05: 949,\n",
       "         57.93: 167,\n",
       "         5.48: 2365,\n",
       "         3.19: 3920,\n",
       "         15.45: 866,\n",
       "         22.92: 512,\n",
       "         59.56: 152,\n",
       "         49.77: 172,\n",
       "         85.41: 77,\n",
       "         100.09: 63,\n",
       "         53.77: 219,\n",
       "         16.5: 740,\n",
       "         340.16: 5,\n",
       "         5.4: 2470,\n",
       "         46.29: 241,\n",
       "         156.99: 21,\n",
       "         12.81: 1042,\n",
       "         11.87: 1097,\n",
       "         54.15: 174,\n",
       "         65.29: 128,\n",
       "         39.37: 314,\n",
       "         14.81: 881,\n",
       "         1.22: 8447,\n",
       "         13.84: 888,\n",
       "         74.21: 119,\n",
       "         85.69: 85,\n",
       "         8.69: 1527,\n",
       "         33.7: 337,\n",
       "         17.33: 702,\n",
       "         4.64: 2773,\n",
       "         10.78: 1222,\n",
       "         12.46: 1082,\n",
       "         5.96: 2120,\n",
       "         5.9: 2231,\n",
       "         17.85: 725,\n",
       "         8.86: 1491,\n",
       "         3.55: 3583,\n",
       "         6.4: 2111,\n",
       "         2.14: 5508,\n",
       "         21.13: 556,\n",
       "         26.95: 446,\n",
       "         71.89: 137,\n",
       "         43.3: 249,\n",
       "         17.27: 743,\n",
       "         9.8: 1315,\n",
       "         22.72: 563,\n",
       "         31.12: 383,\n",
       "         16.98: 778,\n",
       "         17.42: 765,\n",
       "         26.17: 466,\n",
       "         10.18: 1340,\n",
       "         35.44: 320,\n",
       "         69.39: 126,\n",
       "         6.32: 2014,\n",
       "         10.79: 1160,\n",
       "         5.44: 2410,\n",
       "         13.42: 947,\n",
       "         302.57: 4,\n",
       "         87.05: 85,\n",
       "         99.67: 49,\n",
       "         111.22: 55,\n",
       "         13.25: 1041,\n",
       "         35.2: 342,\n",
       "         62.22: 156,\n",
       "         26.11: 430,\n",
       "         28.64: 442,\n",
       "         22.94: 487,\n",
       "         16.81: 803,\n",
       "         23.81: 507,\n",
       "         16.25: 816,\n",
       "         8.25: 1610,\n",
       "         131.47: 24,\n",
       "         94.89: 68,\n",
       "         68.29: 103,\n",
       "         21.31: 594,\n",
       "         23.38: 517,\n",
       "         3.68: 3563,\n",
       "         20.48: 571,\n",
       "         52.79: 190,\n",
       "         3.91: 3245,\n",
       "         5.86: 2255,\n",
       "         3.13: 3995,\n",
       "         14.47: 864,\n",
       "         4.46: 2863,\n",
       "         6.31: 2044,\n",
       "         4.53: 2930,\n",
       "         8.18: 1595,\n",
       "         21.28: 606,\n",
       "         31.27: 370,\n",
       "         40.2: 242,\n",
       "         6.52: 1970,\n",
       "         10.34: 1321,\n",
       "         4.68: 2755,\n",
       "         14.72: 894,\n",
       "         12.29: 1080,\n",
       "         108.99: 46,\n",
       "         138.67: 26,\n",
       "         49.71: 193,\n",
       "         44.21: 240,\n",
       "         20.19: 603,\n",
       "         237.45: 9,\n",
       "         40.71: 279,\n",
       "         65.94: 131,\n",
       "         23.97: 503,\n",
       "         62.74: 133,\n",
       "         44.56: 226,\n",
       "         37.11: 308,\n",
       "         2.91: 4302,\n",
       "         1.61: 6847,\n",
       "         37.7: 289,\n",
       "         217.31: 6,\n",
       "         41.87: 260,\n",
       "         48.94: 202,\n",
       "         3.48: 3540,\n",
       "         102.29: 50,\n",
       "         104.29: 52,\n",
       "         4.55: 2758,\n",
       "         3.96: 3260,\n",
       "         11.57: 1131,\n",
       "         16.15: 769,\n",
       "         11.74: 1054,\n",
       "         14.39: 935,\n",
       "         57.92: 158,\n",
       "         28.41: 391,\n",
       "         61.08: 149,\n",
       "         65.56: 125,\n",
       "         15.21: 881,\n",
       "         32.13: 367,\n",
       "         22.02: 565,\n",
       "         6.55: 2029,\n",
       "         16.34: 778,\n",
       "         11.91: 1106,\n",
       "         8.77: 1496,\n",
       "         23.45: 550,\n",
       "         11.6: 1105,\n",
       "         4.61: 2802,\n",
       "         25.92: 461,\n",
       "         46.69: 240,\n",
       "         44.78: 230,\n",
       "         3.99: 3162,\n",
       "         103.98: 59,\n",
       "         19.93: 627,\n",
       "         3.17: 3932,\n",
       "         27.52: 440,\n",
       "         31.41: 377,\n",
       "         4.08: 3194,\n",
       "         15.27: 861,\n",
       "         10.27: 1287,\n",
       "         18.23: 729,\n",
       "         19.98: 636,\n",
       "         9.98: 1311,\n",
       "         20.55: 661,\n",
       "         133.44: 33,\n",
       "         46.34: 227,\n",
       "         108.77: 40,\n",
       "         27.39: 446,\n",
       "         32.91: 338,\n",
       "         69.18: 135,\n",
       "         17.82: 704,\n",
       "         45.54: 206,\n",
       "         35.92: 305,\n",
       "         19.74: 607,\n",
       "         2.32: 5257,\n",
       "         10.55: 1287,\n",
       "         281.49: 3,\n",
       "         133.4: 30,\n",
       "         201.82: 7,\n",
       "         275.49: 5,\n",
       "         239.41: 6,\n",
       "         28.28: 397,\n",
       "         54.2: 184,\n",
       "         0.74: 11611,\n",
       "         65.26: 125,\n",
       "         63.9: 138,\n",
       "         28.94: 369,\n",
       "         9.37: 1377,\n",
       "         25.24: 479,\n",
       "         153.14: 27,\n",
       "         10.59: 1269,\n",
       "         74.45: 100,\n",
       "         104.75: 49,\n",
       "         2.89: 4287,\n",
       "         27.55: 413,\n",
       "         25.02: 563,\n",
       "         23.06: 549,\n",
       "         34.3: 337,\n",
       "         18.88: 686,\n",
       "         25.2: 470,\n",
       "         14.56: 915,\n",
       "         3.59: 3505,\n",
       "         6.18: 2103,\n",
       "         10.32: 1289,\n",
       "         4.21: 2969,\n",
       "         37.54: 302,\n",
       "         3.73: 3427,\n",
       "         4.22: 3029,\n",
       "         2.51: 4962,\n",
       "         5.11: 2585,\n",
       "         12.31: 1094,\n",
       "         20.14: 613,\n",
       "         6.19: 2210,\n",
       "         5.2: 2540,\n",
       "         3.58: 3605,\n",
       "         3.44: 3701,\n",
       "         5.37: 2419,\n",
       "         12.7: 980,\n",
       "         5.34: 2489,\n",
       "         27.47: 399,\n",
       "         8.66: 1483,\n",
       "         8.89: 1496,\n",
       "         6.84: 1936,\n",
       "         3.39: 3721,\n",
       "         0.95: 9710,\n",
       "         42.33: 239,\n",
       "         7.29: 1831,\n",
       "         3.38: 3682,\n",
       "         1.54: 7146,\n",
       "         2.44: 4988,\n",
       "         11.61: 1141,\n",
       "         0.87: 10173,\n",
       "         4.15: 3155,\n",
       "         18.67: 681,\n",
       "         7.16: 1870,\n",
       "         6.33: 2106,\n",
       "         7.61: 1668,\n",
       "         7.47: 1726,\n",
       "         9.5: 1419,\n",
       "         2.09: 5589,\n",
       "         3.34: 3794,\n",
       "         3.62: 3478,\n",
       "         1.1: 9018,\n",
       "         5.63: 2299,\n",
       "         3.1: 4019,\n",
       "         2.64: 4753,\n",
       "         2.43: 4895,\n",
       "         4.99: 2576,\n",
       "         4.17: 3028,\n",
       "         4.87: 2593,\n",
       "         5.83: 2314,\n",
       "         9.15: 1502,\n",
       "         3.31: 3804,\n",
       "         6.12: 2201,\n",
       "         8.73: 1565,\n",
       "         14.28: 884,\n",
       "         9.09: 1451,\n",
       "         5.92: 2165,\n",
       "         12.06: 1052,\n",
       "         3.52: 3635,\n",
       "         25.39: 528,\n",
       "         20.5: 624,\n",
       "         53.11: 197,\n",
       "         134.1: 25,\n",
       "         91.08: 64,\n",
       "         61.69: 169,\n",
       "         238.74: 7,\n",
       "         122.21: 36,\n",
       "         128.55: 47,\n",
       "         94.32: 66,\n",
       "         12.6: 1053,\n",
       "         114.84: 52,\n",
       "         35.98: 317,\n",
       "         31.75: 383,\n",
       "         13.31: 942,\n",
       "         66.38: 117,\n",
       "         2.79: 4410,\n",
       "         42.22: 239,\n",
       "         26.92: 441,\n",
       "         15.23: 881,\n",
       "         15.04: 869,\n",
       "         2.61: 4642,\n",
       "         43.07: 216,\n",
       "         17.7: 699,\n",
       "         5.28: 2495,\n",
       "         9.94: 1349,\n",
       "         1.68: 6422,\n",
       "         6.98: 1993,\n",
       "         0.8: 10776,\n",
       "         4.59: 2875,\n",
       "         6.28: 2043,\n",
       "         1.11: 8918,\n",
       "         156.7: 19,\n",
       "         176.05: 16,\n",
       "         229.39: 12,\n",
       "         183.27: 12,\n",
       "         30.4: 402,\n",
       "         14.7: 889,\n",
       "         2.18: 5361,\n",
       "         12.11: 1098,\n",
       "         27.19: 449,\n",
       "         5.06: 2609,\n",
       "         38.09: 298,\n",
       "         859.95: 1,\n",
       "         37.9: 256,\n",
       "         118.21: 53,\n",
       "         2.08: 5658,\n",
       "         24.65: 493,\n",
       "         79.83: 93,\n",
       "         30.84: 393,\n",
       "         7.45: 1756,\n",
       "         2.0: 5837,\n",
       "         2.67: 4588,\n",
       "         6.64: 2041,\n",
       "         35.68: 324,\n",
       "         5.31: 2373,\n",
       "         0.88: 10300,\n",
       "         1.56: 6998,\n",
       "         4.88: 2674,\n",
       "         8.83: 1474,\n",
       "         2.84: 4433,\n",
       "         30.74: 372,\n",
       "         9.41: 1343,\n",
       "         4.54: 2720,\n",
       "         1.75: 6502,\n",
       "         6.24: 2079,\n",
       "         9.64: 1363,\n",
       "         1.3: 7895,\n",
       "         100.15: 60,\n",
       "         7.39: 1748,\n",
       "         2.15: 5573,\n",
       "         0.28: 18971,\n",
       "         1.29: 7891,\n",
       "         2.8: 4280,\n",
       "         218.68: 5,\n",
       "         0.7: 11854,\n",
       "         7.42: 1765,\n",
       "         9.72: 1315,\n",
       "         12.16: 1089,\n",
       "         20.98: 584,\n",
       "         4.76: 2706,\n",
       "         10.22: 1303,\n",
       "         3.77: 3459,\n",
       "         3.04: 4044,\n",
       "         1.53: 7145,\n",
       "         1.7: 6593,\n",
       "         1.43: 7578,\n",
       "         3.2: 4014,\n",
       "         10.23: 1282,\n",
       "         17.37: 770,\n",
       "         7.59: 1758,\n",
       "         5.17: 2496,\n",
       "         2.2: 5224,\n",
       "         4.34: 2875,\n",
       "         5.33: 2391,\n",
       "         11.8: 1081,\n",
       "         4.25: 3080,\n",
       "         3.71: 3414,\n",
       "         1.55: 6939,\n",
       "         5.93: 2179,\n",
       "         11.92: 1168,\n",
       "         1.13: 8757,\n",
       "         4.03: 3198,\n",
       "         12.47: 1059,\n",
       "         1.87: 6059,\n",
       "         8.91: 1419,\n",
       "         5.47: 2346,\n",
       "         24.36: 504,\n",
       "         20.94: 612,\n",
       "         27.07: 421,\n",
       "         7.31: 1743,\n",
       "         6.77: 1894,\n",
       "         2.69: 4547,\n",
       "         6.62: 1945,\n",
       "         24.58: 530,\n",
       "         15.28: 854,\n",
       "         2.98: 4278,\n",
       "         2.92: 4240,\n",
       "         1.04: 9309,\n",
       "         7.26: 1788,\n",
       "         50.18: 187,\n",
       "         1.2: 8517,\n",
       "         26.18: 457,\n",
       "         40.08: 242,\n",
       "         0.86: 10340,\n",
       "         33.98: 361,\n",
       "         20.78: 596,\n",
       "         92.47: 89,\n",
       "         10.33: 1242,\n",
       "         4.86: 2655,\n",
       "         3.14: 4026,\n",
       "         5.14: 2581,\n",
       "         45.57: 225,\n",
       "         103.0: 61,\n",
       "         2.5: 4905,\n",
       "         14.23: 939,\n",
       "         2.9: 4255,\n",
       "         3.85: 3243,\n",
       "         17.92: 763,\n",
       "         1.24: 8201,\n",
       "         7.52: 1746,\n",
       "         8.85: 1509,\n",
       "         7.99: 1754,\n",
       "         8.34: 1603,\n",
       "         14.64: 853,\n",
       "         10.46: 1261,\n",
       "         6.43: 2065,\n",
       "         16.84: 716,\n",
       "         19.71: 654,\n",
       "         13.78: 931,\n",
       "         5.97: 2226,\n",
       "         9.78: 1359,\n",
       "         2.03: 5783,\n",
       "         1.32: 7880,\n",
       "         4.93: 2592,\n",
       "         16.36: 803,\n",
       "         34.02: 342,\n",
       "         11.89: 1063,\n",
       "         21.91: 576,\n",
       "         24.66: 484,\n",
       "         10.45: 1218,\n",
       "         10.51: 1252,\n",
       "         1.25: 8106,\n",
       "         16.61: 772,\n",
       "         7.1: 1878,\n",
       "         19.97: 660,\n",
       "         89.82: 64,\n",
       "         59.83: 148,\n",
       "         30.21: 406,\n",
       "         1.21: 8167,\n",
       "         3.92: 3242,\n",
       "         4.97: 2477,\n",
       "         2.38: 5163,\n",
       "         1.34: 7929,\n",
       "         5.19: 2536,\n",
       "         14.08: 907,\n",
       "         35.97: 319,\n",
       "         6.87: 1887,\n",
       "         1.4: 7636,\n",
       "         8.99: 1515,\n",
       "         4.33: 3010,\n",
       "         26.58: 486,\n",
       "         6.34: 2108,\n",
       "         5.57: 2399,\n",
       "         12.09: 1056,\n",
       "         13.67: 984,\n",
       "         5.38: 2380,\n",
       "         8.2: 1628,\n",
       "         9.69: 1395,\n",
       "         3.76: 3401,\n",
       "         6.16: 2136,\n",
       "         5.18: 2533,\n",
       "         27.89: 453,\n",
       "         1.59: 6993,\n",
       "         14.93: 861,\n",
       "         13.82: 940,\n",
       "         4.98: 2589,\n",
       "         6.76: 1994,\n",
       "         24.35: 515,\n",
       "         20.83: 595,\n",
       "         3.27: 3948,\n",
       "         47.61: 190,\n",
       "         51.71: 203,\n",
       "         17.59: 718,\n",
       "         3.93: 3208,\n",
       "         0.76: 11276,\n",
       "         9.88: 1348,\n",
       "         23.77: 505,\n",
       "         13.71: 908,\n",
       "         6.1: 2162,\n",
       "         3.25: 3790,\n",
       "         5.68: 2290,\n",
       "         6.48: 2069,\n",
       "         4.0: 3317,\n",
       "         18.38: 672,\n",
       "         7.97: 1679,\n",
       "         41.57: 267,\n",
       "         20.65: 583,\n",
       "         8.43: 1589,\n",
       "         6.73: 1979,\n",
       "         16.01: 774,\n",
       "         1.76: 6326,\n",
       "         16.08: 772,\n",
       "         7.38: 1894,\n",
       "         9.66: 1328,\n",
       "         37.52: 294,\n",
       "         1.66: 6798,\n",
       "         1.69: 6493,\n",
       "         36.92: 288,\n",
       "         41.96: 250,\n",
       "         14.99: 849,\n",
       "         2.58: 4631,\n",
       "         3.75: 3453,\n",
       "         15.0: 823,\n",
       "         5.3: 2497,\n",
       "         51.28: 190,\n",
       "         1.86: 6073,\n",
       "         9.73: 1351,\n",
       "         19.47: 679,\n",
       "         14.87: 888,\n",
       "         7.05: 1863,\n",
       "         5.67: 2281,\n",
       "         23.18: 545,\n",
       "         9.26: 1418,\n",
       "         1.92: 6031,\n",
       "         11.24: 1148,\n",
       "         10.48: 1246,\n",
       "         20.2: 630,\n",
       "         10.65: 1227,\n",
       "         62.81: 146,\n",
       "         1.78: 6309,\n",
       "         23.73: 474,\n",
       "         11.02: 1240,\n",
       "         0.63: 12724,\n",
       "         7.11: 1819,\n",
       "         31.65: 354,\n",
       "         6.94: 1918,\n",
       "         9.68: 1319,\n",
       "         10.47: 1273,\n",
       "         4.75: 2677,\n",
       "         18.31: 655,\n",
       "         0.83: 10512,\n",
       "         33.13: 345,\n",
       "         7.72: 1710,\n",
       "         61.99: 124,\n",
       "         2.68: 4483,\n",
       "         12.52: 983,\n",
       "         11.06: 1210,\n",
       "         46.74: 230,\n",
       "         3.42: 3785,\n",
       "         53.36: 167,\n",
       "         14.66: 889,\n",
       "         14.5: 897,\n",
       "         13.65: 981,\n",
       "         2.47: 5027,\n",
       "         19.3: 600,\n",
       "         12.91: 1017,\n",
       "         5.53: 2426,\n",
       "         9.81: 1325,\n",
       "         17.47: 698,\n",
       "         3.22: 3854,\n",
       "         39.02: 270,\n",
       "         18.12: 702,\n",
       "         17.19: 715,\n",
       "         113.28: 64,\n",
       "         38.08: 281,\n",
       "         12.49: 1042,\n",
       "         70.76: 108,\n",
       "         11.51: 1113,\n",
       "         11.37: 1142,\n",
       "         5.16: 2508,\n",
       "         7.17: 1829,\n",
       "         2.3: 5179,\n",
       "         3.65: 3471,\n",
       "         8.5: 1663,\n",
       "         1.71: 6453,\n",
       "         4.74: 2649,\n",
       "         1.83: 6289,\n",
       "         2.81: 4486,\n",
       "         11.88: 1078,\n",
       "         20.44: 626,\n",
       "         20.45: 599,\n",
       "         2.13: 5630,\n",
       "         13.57: 953,\n",
       "         5.04: 2591,\n",
       "         8.09: 1699,\n",
       "         48.02: 203,\n",
       "         2.07: 5558,\n",
       "         49.69: 224,\n",
       "         8.6: 1502,\n",
       "         14.15: 927,\n",
       "         10.07: 1292,\n",
       "         26.34: 487,\n",
       "         6.93: 1849,\n",
       "         12.33: 1079,\n",
       "         10.66: 1272,\n",
       "         35.1: 307,\n",
       "         14.8: 860,\n",
       "         54.66: 196,\n",
       "         7.18: 1864,\n",
       "         13.3: 964,\n",
       "         11.4: 1129,\n",
       "         6.26: 2069,\n",
       "         26.85: 451,\n",
       "         4.91: 2636,\n",
       "         1.64: 6663,\n",
       "         17.54: 745,\n",
       "         13.35: 951,\n",
       "         12.15: 1088,\n",
       "         16.96: 749,\n",
       "         72.09: 111,\n",
       "         9.49: 1351,\n",
       "         3.53: 3601,\n",
       "         19.83: 612,\n",
       "         26.99: 448,\n",
       "         20.21: 601,\n",
       "         6.9: 1857,\n",
       "         2.71: 4647,\n",
       "         11.52: 1182,\n",
       "         9.28: 1472,\n",
       "         68.06: 144,\n",
       "         9.33: 1403,\n",
       "         14.02: 902,\n",
       "         8.0: 1713,\n",
       "         12.19: 1096,\n",
       "         15.26: 845,\n",
       "         13.29: 954,\n",
       "         9.7: 1289,\n",
       "         26.5: 425,\n",
       "         3.82: 3343,\n",
       "         1.85: 6099,\n",
       "         10.74: 1290,\n",
       "         27.27: 482,\n",
       "         17.31: 772,\n",
       "         54.41: 180,\n",
       "         8.38: 1531,\n",
       "         20.9: 618,\n",
       "         21.08: 604,\n",
       "         11.49: 1129,\n",
       "         14.21: 871,\n",
       "         21.79: 574,\n",
       "         15.43: 798,\n",
       "         7.73: 1840,\n",
       "         1.84: 6134,\n",
       "         15.07: 867,\n",
       "         2.22: 5241,\n",
       "         11.77: 1017,\n",
       "         3.01: 4256,\n",
       "         5.7: 2377,\n",
       "         9.76: 1350,\n",
       "         28.25: 437,\n",
       "         30.33: 370,\n",
       "         47.23: 262,\n",
       "         29.1: 358,\n",
       "         14.4: 944,\n",
       "         31.85: 354,\n",
       "         9.46: 1393,\n",
       "         15.89: 770,\n",
       "         32.08: 356,\n",
       "         43.2: 255,\n",
       "         17.74: 721,\n",
       "         4.04: 3224,\n",
       "         1.73: 6553,\n",
       "         10.49: 1249,\n",
       "         23.72: 557,\n",
       "         8.97: 1466,\n",
       "         10.6: 1330,\n",
       "         11.82: 1064,\n",
       "         25.32: 520,\n",
       "         37.3: 288,\n",
       "         10.84: 1266,\n",
       "         9.85: 1365,\n",
       "         133.23: 32,\n",
       "         55.73: 162,\n",
       "         5.22: 2458,\n",
       "         0.6: 13007,\n",
       "         3.86: 3344,\n",
       "         7.49: 1702,\n",
       "         7.44: 1815,\n",
       "         9.03: 1419,\n",
       "         24.43: 531,\n",
       "         6.95: 1874,\n",
       "         31.54: 375,\n",
       "         111.55: 43,\n",
       "         41.0: 254,\n",
       "         25.03: 504,\n",
       "         9.53: 1433,\n",
       "         18.93: 648,\n",
       "         7.06: 1790,\n",
       "         33.22: 337,\n",
       "         152.86: 29,\n",
       "         5.07: 2499,\n",
       "         10.38: 1364,\n",
       "         10.72: 1263,\n",
       "         16.43: 802,\n",
       "         25.22: 487,\n",
       "         20.58: 655,\n",
       "         49.28: 216,\n",
       "         4.36: 2945,\n",
       "         51.78: 172,\n",
       "         16.42: 768,\n",
       "         23.62: 518,\n",
       "         23.54: 540,\n",
       "         27.79: 395,\n",
       "         151.79: 17,\n",
       "         23.8: 531,\n",
       "         21.41: 570,\n",
       "         17.51: 796,\n",
       "         44.86: 225,\n",
       "         7.43: 1780,\n",
       "         16.32: 790,\n",
       "         78.23: 95,\n",
       "         85.68: 89,\n",
       "         8.52: 1557,\n",
       "         ...})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(app_usage.rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "32f88032-d398-42f2-ba28-bfb39b1e6c83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({26: 5518,\n",
       "         6: 3730,\n",
       "         20: 5782,\n",
       "         28: 5441,\n",
       "         83: 179,\n",
       "         23: 5753,\n",
       "         3: 2630,\n",
       "         41: 3249,\n",
       "         86: 137,\n",
       "         71: 426,\n",
       "         16: 5468,\n",
       "         40: 3416,\n",
       "         27: 5367,\n",
       "         34: 4369,\n",
       "         17: 5539,\n",
       "         30: 4982,\n",
       "         66: 622,\n",
       "         76: 299,\n",
       "         2: 2391,\n",
       "         18: 5719,\n",
       "         42: 3058,\n",
       "         54: 1533,\n",
       "         95: 89,\n",
       "         51: 1795,\n",
       "         31: 4982,\n",
       "         49: 2074,\n",
       "         22: 5719,\n",
       "         7: 4134,\n",
       "         24: 5644,\n",
       "         37: 3984,\n",
       "         13: 5045,\n",
       "         39: 3604,\n",
       "         12: 4930,\n",
       "         9: 4332,\n",
       "         19: 5665,\n",
       "         35: 4243,\n",
       "         14: 5330,\n",
       "         38: 3816,\n",
       "         62: 827,\n",
       "         4: 2960,\n",
       "         11: 4653,\n",
       "         36: 4215,\n",
       "         50: 2008,\n",
       "         48: 2310,\n",
       "         25: 5591,\n",
       "         45: 2666,\n",
       "         21: 5719,\n",
       "         8: 4119,\n",
       "         15: 5555,\n",
       "         57: 1270,\n",
       "         98: 61,\n",
       "         33: 4622,\n",
       "         29: 5198,\n",
       "         47: 2313,\n",
       "         10: 4528,\n",
       "         72: 404,\n",
       "         5: 3485,\n",
       "         52: 1659,\n",
       "         43: 2969,\n",
       "         1: 2351,\n",
       "         32: 4748,\n",
       "         58: 1131,\n",
       "         44: 2804,\n",
       "         69: 495,\n",
       "         107: 35,\n",
       "         79: 219,\n",
       "         111: 25,\n",
       "         53: 1623,\n",
       "         65: 713,\n",
       "         70: 472,\n",
       "         56: 1329,\n",
       "         61: 897,\n",
       "         64: 730,\n",
       "         55: 1450,\n",
       "         60: 1029,\n",
       "         89: 95,\n",
       "         81: 234,\n",
       "         84: 163,\n",
       "         110: 29,\n",
       "         67: 576,\n",
       "         78: 298,\n",
       "         46: 2473,\n",
       "         63: 839,\n",
       "         116: 16,\n",
       "         147: 6,\n",
       "         68: 566,\n",
       "         134: 7,\n",
       "         88: 141,\n",
       "         105: 31,\n",
       "         59: 1093,\n",
       "         73: 370,\n",
       "         80: 215,\n",
       "         101: 60,\n",
       "         93: 83,\n",
       "         108: 42,\n",
       "         77: 290,\n",
       "         74: 343,\n",
       "         94: 98,\n",
       "         82: 191,\n",
       "         87: 131,\n",
       "         85: 145,\n",
       "         90: 106,\n",
       "         92: 95,\n",
       "         102: 41,\n",
       "         122: 10,\n",
       "         75: 350,\n",
       "         100: 38,\n",
       "         112: 21,\n",
       "         103: 40,\n",
       "         96: 60,\n",
       "         91: 113,\n",
       "         139: 3,\n",
       "         157: 1,\n",
       "         120: 11,\n",
       "         132: 6,\n",
       "         143: 2,\n",
       "         106: 25,\n",
       "         125: 8,\n",
       "         97: 51,\n",
       "         146: 4,\n",
       "         109: 23,\n",
       "         114: 23,\n",
       "         123: 6,\n",
       "         117: 12,\n",
       "         99: 50,\n",
       "         133: 8,\n",
       "         121: 8,\n",
       "         104: 29,\n",
       "         113: 23,\n",
       "         144: 2,\n",
       "         131: 5,\n",
       "         163: 1,\n",
       "         115: 18,\n",
       "         141: 4,\n",
       "         176: 1,\n",
       "         182: 2,\n",
       "         229: 1,\n",
       "         127: 9,\n",
       "         130: 3,\n",
       "         129: 8,\n",
       "         119: 14,\n",
       "         138: 3,\n",
       "         135: 3,\n",
       "         161: 1,\n",
       "         142: 1,\n",
       "         118: 8,\n",
       "         173: 2,\n",
       "         145: 3,\n",
       "         149: 1,\n",
       "         137: 3,\n",
       "         136: 5,\n",
       "         162: 2,\n",
       "         169: 4,\n",
       "         180: 1,\n",
       "         197: 1,\n",
       "         126: 3,\n",
       "         153: 2,\n",
       "         178: 2,\n",
       "         124: 9,\n",
       "         236: 1,\n",
       "         159: 1,\n",
       "         128: 8,\n",
       "         151: 2,\n",
       "         155: 2,\n",
       "         160: 1,\n",
       "         220: 1,\n",
       "         201: 1,\n",
       "         195: 1,\n",
       "         207: 1,\n",
       "         189: 1,\n",
       "         246: 1,\n",
       "         179: 1,\n",
       "         150: 2,\n",
       "         140: 2,\n",
       "         164: 1,\n",
       "         154: 2,\n",
       "         152: 1,\n",
       "         226: 1,\n",
       "         172: 1,\n",
       "         187: 1,\n",
       "         177: 1,\n",
       "         175: 1})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(app_usage.groupby(['uid']).count()['item_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dba71981-3cc8-4ae6-b136-08c482b5b406",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28.649443781612867"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Average number of ratings per user\n",
    "np.mean(app_usage.groupby(['uid']).count()['item_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "93c74864-3ab0-4ed9-9ea1-a719775838b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, valid_df = train_test_split(app_usage, test_size=0.2)\n",
    "\n",
    "#resetting indices to avoid indexing errors in the future\n",
    "train_df = train_df.reset_index()[['uid', 'item_id', 'rating']]\n",
    "valid_df = valid_df.reset_index()[['uid', 'item_id', 'rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "52a28d08-962a-4a90-8397-122533a2d6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_column(column):\n",
    "    \"\"\" Encodes a pandas column with continous IDs\"\"\"\n",
    "    keys = column.unique()\n",
    "    key_to_id = {key:idx for idx,key in enumerate(keys)}\n",
    "    return key_to_id, np.array([key_to_id[x] for x in column]), len(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4ac16e48-bd0b-4cf3-b53c-ce5694e85cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_df(user_df):\n",
    "    \"\"\"Encodes rating data with continuous user and an item ids\"\"\"\n",
    "    \n",
    "    item_ids, user_df['item_id'], num_item = encode_column(user_df['item_id'])\n",
    "    user_ids, user_df['uid'], num_users = encode_column(user_df['uid'])\n",
    "    return user_df, num_users, num_item, user_ids, item_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "19e8fb6c-d560-475d-b138-b8ae63f7e950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users : 237456\n",
      "Number of apps : 43509\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>47.56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   uid  item_id  rating\n",
       "0    0        0    4.45\n",
       "1    1        1    6.23\n",
       "2    2        2    3.68\n",
       "3    3        3    6.96\n",
       "4    4        4   47.56"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_df, num_users, num_item, user_ids, item_ids = encode_df(train_df)\n",
    "print(\"Number of users :\", num_users)\n",
    "print(\"Number of apps :\", num_item)\n",
    "user_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9e5ef4d2-8b53-44b3-98fe-5ebe431c4fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embeddings(n, K):\n",
    "    \"\"\"\n",
    "    Creates a random numpy matrix of shape n, K with uniform values in (0, 11/K)\n",
    "    n: number of items/users\n",
    "    K: number of factors in the embedding \n",
    "    \"\"\"\n",
    "    return 11*np.random.random((n, K)) / K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "afb8ae4c-0651-48e6-9aee-eb226fd77b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sparse_matrix(df, rows, cols, column_name=\"rating\"):\n",
    "    \"\"\" Returns a sparse utility matrix\"\"\" \n",
    "    return sparse.csc_matrix((df[column_name].values,(df['uid'].values, df['item_id'].values)),shape=(rows, cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "26be1519-39c7-438c-8509-f48c79a97151",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df, num_users, num_item, user_ids, item_ids = encode_df(train_df)\n",
    "Y = create_sparse_matrix(user_df, num_users, num_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "89a77930-27e9-4b02-a775-d8686c052a7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[21.81,  0.  ,  0.  , ...,  0.  ,  0.  ,  0.  ],\n",
       "        [ 0.  ,  6.23,  0.  , ...,  0.  ,  0.  ,  0.  ],\n",
       "        [ 0.  ,  0.  ,  3.68, ...,  0.  ,  0.  ,  0.  ],\n",
       "        ...,\n",
       "        [ 0.  ,  0.  ,  0.  , ...,  0.  ,  0.  ,  0.  ],\n",
       "        [ 0.  ,  0.  ,  0.  , ...,  0.  ,  0.  ,  0.  ],\n",
       "        [ 0.  ,  0.  ,  0.  , ...,  0.  ,  0.  ,  0.  ]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7d238145-65f7-4b5a-9cd8-b8af4c362373",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(df, emb_user, emb_item):\n",
    "    \"\"\" This function computes df[\"prediction\"] without doing (U*V^T).\n",
    "    \n",
    "    Computes df[\"prediction\"] by using elementwise multiplication of the corresponding embeddings and then \n",
    "    sum to get the prediction u_i*v_j. This avoids creating the dense matrix U*V^T.\n",
    "    \"\"\"\n",
    "    df['prediction'] = np.sum(np.multiply(emb_item[df['item_id']],emb_user[df['uid']]), axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7a04a244-359d-4531-8501-411730fb7f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lmbda = 0.0002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8748d86e-235b-4b7d-a061-09d25025b925",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(df, emb_user, emb_item):\n",
    "    \"\"\" Computes mean square error\"\"\"\n",
    "    Y = create_sparse_matrix(df, emb_user.shape[0], emb_item.shape[0])\n",
    "    predicted = create_sparse_matrix(predict(df, emb_user, emb_item), emb_user.shape[0], emb_item.shape[0], 'prediction')\n",
    "    return np.sum((Y-predicted).power(2))/df.shape[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "434bfd33-3dd0-4e55-996c-72b5b1893d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(df, emb_user, emb_item):\n",
    "    \"\"\" Computes the gradient for user and item embeddings\"\"\"\n",
    "    Y = create_sparse_matrix(df, emb_user.shape[0], emb_item.shape[0])\n",
    "    predicted = create_sparse_matrix(predict(df, emb_user, emb_item), emb_user.shape[0], emb_item.shape[0], 'prediction')\n",
    "    delta =(Y-predicted)\n",
    "    grad_user = (-2/df.shape[0])*(delta*emb_item) + 2*lmbda*emb_user\n",
    "    grad_item = (-2/df.shape[0])*(delta.T*emb_user) + 2*lmbda*emb_item\n",
    "    return grad_user, grad_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bc7b8ba8-12af-43d1-909e-0a208b5d9f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(df, emb_user, emb_item, iterations=2000, learning_rate=0.01, df_val=None):\n",
    "    \"\"\" \n",
    "    Computes gradient descent with momentum (0.9) for given number of iterations.\n",
    "    emb_user: the trained user embedding\n",
    "    emb_item: the trained item embedding\n",
    "    \"\"\"\n",
    "    Y = create_sparse_matrix(df, emb_user.shape[0], emb_item.shape[0])\n",
    "    beta = 0.9\n",
    "    grad_user, grad_item = gradient(df, emb_user, emb_item)\n",
    "    v_user = grad_user\n",
    "    v_item = grad_item\n",
    "    for i in range(iterations):\n",
    "        grad_user, grad_item = gradient(df, emb_user, emb_item)\n",
    "        v_user = beta*v_user + (1-beta)*grad_user\n",
    "        v_item = beta*v_item + (1-beta)*grad_item\n",
    "        emb_user = emb_user - learning_rate*v_user\n",
    "        emb_item = emb_item - learning_rate*v_item\n",
    "        if(not (i+1)%50):\n",
    "            print(\"\\niteration\", i+1, \":\")\n",
    "            print(\"train mse:\",  cost(df, emb_user, emb_item))\n",
    "            if df_val is not None:\n",
    "                print(\"validation mse:\",  cost(df_val, emb_user, emb_item))\n",
    "    return emb_user, emb_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bee6aa1d-a053-43d5-b486-91d8a9ea5c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iteration 50 :\n",
      "train mse: 6015.186376456335\n",
      "\n",
      "iteration 100 :\n",
      "train mse: 5687.048604988224\n",
      "\n",
      "iteration 150 :\n",
      "train mse: 5489.0217810815975\n",
      "\n",
      "iteration 200 :\n",
      "train mse: 5305.234511131506\n",
      "\n",
      "iteration 250 :\n",
      "train mse: 5132.559546858968\n",
      "\n",
      "iteration 300 :\n",
      "train mse: 4971.033879431151\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [29]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m emb_user \u001b[38;5;241m=\u001b[39m create_embeddings(num_users, \u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m      2\u001b[0m emb_item \u001b[38;5;241m=\u001b[39m create_embeddings(num_item, \u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m emb_user, emb_item \u001b[38;5;241m=\u001b[39m \u001b[43mgradient_descent\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43memb_user\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43memb_item\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m800\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [28]\u001b[0m, in \u001b[0;36mgradient_descent\u001b[0;34m(df, emb_user, emb_item, iterations, learning_rate, df_val)\u001b[0m\n\u001b[1;32m     11\u001b[0m v_item \u001b[38;5;241m=\u001b[39m grad_item\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(iterations):\n\u001b[0;32m---> 13\u001b[0m     grad_user, grad_item \u001b[38;5;241m=\u001b[39m \u001b[43mgradient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43memb_user\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43memb_item\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     v_user \u001b[38;5;241m=\u001b[39m beta\u001b[38;5;241m*\u001b[39mv_user \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39mbeta)\u001b[38;5;241m*\u001b[39mgrad_user\n\u001b[1;32m     15\u001b[0m     v_item \u001b[38;5;241m=\u001b[39m beta\u001b[38;5;241m*\u001b[39mv_item \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39mbeta)\u001b[38;5;241m*\u001b[39mgrad_item\n",
      "Input \u001b[0;32mIn [27]\u001b[0m, in \u001b[0;36mgradient\u001b[0;34m(df, emb_user, emb_item)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03m\"\"\" Computes the gradient for user and item embeddings\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m Y \u001b[38;5;241m=\u001b[39m create_sparse_matrix(df, emb_user\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], emb_item\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m----> 4\u001b[0m predicted \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_sparse_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43memb_user\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43memb_item\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43memb_user\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43memb_item\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprediction\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m delta \u001b[38;5;241m=\u001b[39m(Y\u001b[38;5;241m-\u001b[39mpredicted)\n\u001b[1;32m      6\u001b[0m grad_user \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m/\u001b[39mdf\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m*\u001b[39m(delta\u001b[38;5;241m*\u001b[39memb_item) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39mlmbda\u001b[38;5;241m*\u001b[39memb_user\n",
      "Input \u001b[0;32mIn [21]\u001b[0m, in \u001b[0;36mcreate_sparse_matrix\u001b[0;34m(df, rows, cols, column_name)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_sparse_matrix\u001b[39m(df, rows, cols, column_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrating\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124;03m\"\"\" Returns a sparse utility matrix\"\"\"\u001b[39;00m \n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msparse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcsc_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcolumn_name\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43muid\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mitem_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mrows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcols\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/scipy/sparse/_compressed.py:52\u001b[0m, in \u001b[0;36m_cs_matrix.__init__\u001b[0;34m(self, arg1, shape, dtype, copy)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(arg1) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m     51\u001b[0m         \u001b[38;5;66;03m# (data, ij) format\u001b[39;00m\n\u001b[0;32m---> 52\u001b[0m         other \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_coo_container\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_self(other)\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(arg1) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[1;32m     57\u001b[0m         \u001b[38;5;66;03m# (data, indices, indptr) format\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/scipy/sparse/_compressed.py:33\u001b[0m, in \u001b[0;36m_cs_matrix.__init__\u001b[0;34m(self, arg1, shape, dtype, copy)\u001b[0m\n\u001b[1;32m     31\u001b[0m         arg1 \u001b[38;5;241m=\u001b[39m arg1\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 33\u001b[0m         arg1 \u001b[38;5;241m=\u001b[39m \u001b[43marg1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masformat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_self(arg1)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg1, \u001b[38;5;28mtuple\u001b[39m):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/scipy/sparse/_base.py:376\u001b[0m, in \u001b[0;36mspmatrix.asformat\u001b[0;34m(self, format, copy)\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;66;03m# Forward the copy kwarg, if it's accepted.\u001b[39;00m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 376\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconvert_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    378\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m convert_method()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/scipy/sparse/_coo.py:368\u001b[0m, in \u001b[0;36mcoo_matrix.tocsc\u001b[0;34m(self, copy)\u001b[0m\n\u001b[1;32m    366\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_csc_container((data, indices, indptr), shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhas_canonical_format:\n\u001b[0;32m--> 368\u001b[0m     \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum_duplicates\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/scipy/sparse/_compressed.py:1118\u001b[0m, in \u001b[0;36m_cs_matrix.sum_duplicates\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhas_canonical_format:\n\u001b[1;32m   1117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m-> 1118\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msort_indices\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1120\u001b[0m M, N \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_swap(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m   1121\u001b[0m _sparsetools\u001b[38;5;241m.\u001b[39mcsr_sum_duplicates(M, N, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindptr, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices,\n\u001b[1;32m   1122\u001b[0m                                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/scipy/sparse/_compressed.py:1164\u001b[0m, in \u001b[0;36m_cs_matrix.sort_indices\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1160\u001b[0m \u001b[38;5;124;03m\"\"\"Sort the indices of this matrix *in place*\u001b[39;00m\n\u001b[1;32m   1161\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1163\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhas_sorted_indices:\n\u001b[0;32m-> 1164\u001b[0m     \u001b[43m_sparsetools\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcsr_sort_indices\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindptr\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1165\u001b[0m \u001b[43m                                  \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1166\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhas_sorted_indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "emb_user = create_embeddings(num_users, 3)\n",
    "emb_item = create_embeddings(num_item, 3)\n",
    "emb_user, emb_item = gradient_descent(user_df, emb_user, emb_item, iterations=800, learning_rate=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51256c0b-937f-4ff2-aa5e-f0e02445a3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_new_data(valid_df, user_ids, item_ids):\n",
    "    \"\"\" Encodes valid_df with the same encoding as train_df.\n",
    "    \"\"\"\n",
    "    df_val_chosen = valid_df['item_id'].isin(item_ids.keys()) & valid_df['uid'].isin(user_ids.keys())\n",
    "    valid_df = valid_df[df_val_chosen]\n",
    "    valid_df['item_id'] =  np.array([item_ids[x] for x in valid_df['item_id']])\n",
    "    valid_df['uid'] = np.array([user_ids[x] for x in valid_df['uid']])\n",
    "    return valid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ca23a7-b8b6-42b3-98b2-2290d9967692",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"before encoding:\", valid_df.shape)\n",
    "valid_df = encode_new_data(valid_df, user_ids, item_ids)\n",
    "print(\"after encoding:\", valid_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ee06a7-aa70-4394-a7f8-e129432746fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mse = cost(train_df, emb_user, emb_item)\n",
    "val_mse = cost(valid_df, emb_user, emb_item)\n",
    "print(train_mse, val_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028279bb-0c77-43e6-b8c1-520b77e47812",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e22792-d393-4e1e-8d96-a4b96f644203",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = valid_df[['uid','item_id']].copy()\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41e1cf3-de4b-4919-baa6-ec3f97ed8199",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = sub[sub.uid.isin(validation_data.uid)].astype({\"uid\":'object', \"item_id\":'object'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1cbb299",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149779c2-0bbe-423f-a5c0-1738d5d3d85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = sub.astype({\"uid\":'object', \"item_id\":'object'})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b220f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv(\"submission_from_starter_script.csv\", index = False, header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4547b199-8a18-4146-855d-936712ae52d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "sample_submission=pd.read_csv('sample_submission.csv')\n",
    "stest=pd.read_csv('submission_from_starter_script.csv')\n",
    "common = sample_submission.merge(stest, on=[\"uid\"])\n",
    "result = sample_submission[~sample_submission.uid.isin(common.uid)]\n",
    "new=pd.concat([stest, result], ignore_index = True)\n",
    "new.to_csv(\"submission_from_starter_script_modified.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b46b01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
