{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import cv2\n",
    "from os import listdir\n",
    "from sklearn.preprocessing import LabelBinarizer,LabelEncoder\n",
    "from keras.models import Sequential\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation, Flatten, Dropout, Dense\n",
    "from keras import backend as K\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "# from keras.optimizer_v1 import Adam\n",
    "# from keras.preprocessing import image\n",
    "# from keras.preprocessing.image import img_to_array2\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "import tensorflow\n",
    "tensorflow.random.set_seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.optimizers import adam_v2\n",
    "from tensorflow.keras.optimizers import Adam,SGD\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 3, 3, 3], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_image_size = (60,60)\n",
    "def convert_image_to_array(image_dir):\n",
    "    # if image_dir.split('.')[-1]=='gif':\n",
    "    #     images=Image.open(image_dir).convert('RGB')\n",
    "    #     images = np.asarray(images)\n",
    "    # elif image_dir.split('.')[-1]=='jpg' or image_dir.split('.')[-1]=='JPG' \\\n",
    "    # or image_dir.split('.')[-1]=='png' or image_dir.split('.')[-1]=='jpeg' or image_dir.split('.')[-1]=='jfif':\n",
    "    images=Image.open(image_dir).convert('RGB')\n",
    "    images = np.asarray(images)\n",
    "        # images = cv2.imread(image_dir)\n",
    "    # else:\n",
    "    #     print('Error!')\n",
    "    if images is not None :\n",
    "        images = cv2.resize(images, default_image_size) \n",
    "        images = images / 225.0  \n",
    "        return images\n",
    "    else :\n",
    "        print('Error')\n",
    "        \n",
    "        return np.array([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "548\n",
      "712\n",
      "712\n",
      "591\n"
     ]
    }
   ],
   "source": [
    "print(len(os.listdir(r'C:\\projects\\digit_prediction\\vision_verse\\data\\train\\train\\crownandrootrot')))\n",
    "print(len(os.listdir(r'C:\\projects\\digit_prediction\\vision_verse\\data\\train\\train\\healthywheat')))\n",
    "print(len(os.listdir(r'C:\\projects\\digit_prediction\\vision_verse\\data\\train\\train\\leafrust')))\n",
    "print(len(os.listdir(r'C:\\projects\\digit_prediction\\vision_verse\\data\\train\\train\\wheatloosesmut')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading images ...\n",
      "[INFO] Processing crownandrootrot ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\projects\\digit_prediction\\venv\\lib\\site-packages\\PIL\\Image.py:993: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Processing healthywheat ...\n",
      "[INFO] Processing leafrust ...\n",
      "[INFO] Processing wheatloosesmut ...\n",
      "[INFO] Image loading completed\n"
     ]
    }
   ],
   "source": [
    "\n",
    "basepath = r'C:\\projects\\digit_prediction\\vision_verse\\data\\train\\train'\n",
    "image_list, label_list = [], []\n",
    "\n",
    "print(\"[INFO] Loading images ...\")\n",
    "root_dir = listdir(basepath)\n",
    "\n",
    "for plant_disease_folder in root_dir:\n",
    "    print(f\"[INFO] Processing {plant_disease_folder} ...\")\n",
    "    plant_disease_image_list = listdir(os.path.join(basepath,plant_disease_folder))\n",
    "\n",
    "    for images in plant_disease_image_list:\n",
    "        image_directory = os.path.join(basepath,plant_disease_folder,images)\n",
    "        image_list.append(convert_image_to_array(image_directory))\n",
    "        label_list.append(plant_disease_folder)\n",
    "print(\"[INFO] Image loading completed\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['crownandrootrot' 'healthywheat' 'leafrust' 'wheatloosesmut']\n"
     ]
    }
   ],
   "source": [
    "label_binarizer = LabelEncoder()\n",
    "image_labels = label_binarizer.fit_transform(label_list)\n",
    "# pickle.dump(label_binarizer,open('label_transform.pkl', 'wb'))\n",
    "n_classes = len(label_binarizer.classes_)\n",
    "print(label_binarizer.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list = np.array(image_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Spliting data to train, test\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] Spliting data to train, test\")\n",
    "x_train, x_test, y_train, y_test = train_test_split(image_list, image_labels,stratify=image_labels, test_size=0.2, random_state = 42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# augment = ImageDataGenerator(rotation_range=25, width_shift_range=0.1,\n",
    "#                              height_shift_range=0.1, shear_range=0.2, \n",
    "#                              zoom_range=0.2, horizontal_flip=True, \n",
    "#                              fill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(input_shape=(60,60,3),filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=32,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Conv2D(filters=32, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=32, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Conv2D(filters=64, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=64, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=64, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=1000,activation=\"relu\"))\n",
    "model.add(Dense(units=500,activation=\"relu\"))\n",
    "model.add(Dense(units=250,activation=\"relu\"))\n",
    "model.add(Dense(units=50,activation=\"relu\"))\n",
    "model.add(Dense(units=4, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "81/81 [==============================] - 67s 174ms/step - loss: 1.3755 - accuracy: 0.3059 - val_loss: 1.3817 - val_accuracy: 0.2768\n",
      "Epoch 2/20\n",
      "81/81 [==============================] - 6s 72ms/step - loss: 1.3735 - accuracy: 0.2996 - val_loss: 1.8798 - val_accuracy: 0.4074\n",
      "Epoch 3/20\n",
      "81/81 [==============================] - 6s 72ms/step - loss: 1.3228 - accuracy: 0.3921 - val_loss: 1.1882 - val_accuracy: 0.5010\n",
      "Epoch 4/20\n",
      "81/81 [==============================] - 6s 72ms/step - loss: 1.1823 - accuracy: 0.4764 - val_loss: 1.1230 - val_accuracy: 0.4854\n",
      "Epoch 5/20\n",
      "81/81 [==============================] - 6s 72ms/step - loss: 1.1523 - accuracy: 0.4940 - val_loss: 1.0822 - val_accuracy: 0.5302\n",
      "Epoch 6/20\n",
      "81/81 [==============================] - 6s 72ms/step - loss: 1.0865 - accuracy: 0.5271 - val_loss: 1.0290 - val_accuracy: 0.5556\n",
      "Epoch 7/20\n",
      "81/81 [==============================] - 6s 72ms/step - loss: 1.0701 - accuracy: 0.5349 - val_loss: 1.0283 - val_accuracy: 0.6199\n",
      "Epoch 8/20\n",
      "81/81 [==============================] - 6s 73ms/step - loss: 1.0028 - accuracy: 0.5794 - val_loss: 0.9603 - val_accuracy: 0.6062\n",
      "Epoch 9/20\n",
      "81/81 [==============================] - 6s 73ms/step - loss: 0.9325 - accuracy: 0.6130 - val_loss: 0.8144 - val_accuracy: 0.6803\n",
      "Epoch 10/20\n",
      "81/81 [==============================] - 6s 73ms/step - loss: 0.8517 - accuracy: 0.6625 - val_loss: 0.7913 - val_accuracy: 0.6959\n",
      "Epoch 11/20\n",
      "81/81 [==============================] - 6s 72ms/step - loss: 0.7192 - accuracy: 0.7288 - val_loss: 0.6548 - val_accuracy: 0.7544\n",
      "Epoch 12/20\n",
      "81/81 [==============================] - 6s 72ms/step - loss: 0.5598 - accuracy: 0.7944 - val_loss: 0.4390 - val_accuracy: 0.8460\n",
      "Epoch 13/20\n",
      "81/81 [==============================] - 6s 73ms/step - loss: 0.5107 - accuracy: 0.8096 - val_loss: 0.3756 - val_accuracy: 0.8694\n",
      "Epoch 14/20\n",
      "81/81 [==============================] - 6s 72ms/step - loss: 0.3832 - accuracy: 0.8670 - val_loss: 0.2868 - val_accuracy: 0.9045\n",
      "Epoch 15/20\n",
      "81/81 [==============================] - 6s 72ms/step - loss: 0.3099 - accuracy: 0.8935 - val_loss: 0.2899 - val_accuracy: 0.8947\n",
      "Epoch 16/20\n",
      "81/81 [==============================] - 6s 73ms/step - loss: 0.3206 - accuracy: 0.8974 - val_loss: 0.4673 - val_accuracy: 0.8265\n",
      "Epoch 17/20\n",
      "81/81 [==============================] - 6s 72ms/step - loss: 0.2812 - accuracy: 0.9118 - val_loss: 0.1613 - val_accuracy: 0.9493\n",
      "Epoch 18/20\n",
      "81/81 [==============================] - 6s 72ms/step - loss: 0.1598 - accuracy: 0.9473 - val_loss: 0.1393 - val_accuracy: 0.9513\n",
      "Epoch 19/20\n",
      "81/81 [==============================] - 6s 72ms/step - loss: 0.1325 - accuracy: 0.9555 - val_loss: 0.0812 - val_accuracy: 0.9786\n",
      "Epoch 20/20\n",
      "81/81 [==============================] - 6s 72ms/step - loss: 0.1061 - accuracy: 0.9696 - val_loss: 0.1081 - val_accuracy: 0.9688\n"
     ]
    }
   ],
   "source": [
    "\n",
    "opt =Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "hist = model.fit(image_list,image_labels,epochs=20,verbose=1,validation_data=(x_test,y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9941530129804808\n"
     ]
    }
   ],
   "source": [
    "# print(cnn.evaluate(x_test,y_test))\n",
    "# cnn.fit(x_train, y_train, epochs=50,verbose=1,validation_data=(x_test,y_test))\n",
    "y_pred = model.predict(x_test)\n",
    "y_classes = [np.argmax(element) for element in y_pred]\n",
    "from sklearn.metrics import f1_score\n",
    "print(f1_score(y_test,y_classes,average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 0.902479156153312\n",
    "* 0.924073726300525\n",
    "* 0.978598125154676\n",
    "* 0.9941530129804808"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97       110\n",
      "           1       0.97      0.97      0.97       143\n",
      "           2       1.00      0.99      0.99       142\n",
      "           3       0.98      0.97      0.97       118\n",
      "\n",
      "    accuracy                           0.98       513\n",
      "   macro avg       0.98      0.98      0.98       513\n",
      "weighted avg       0.98      0.98      0.98       513\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(\"Classification Report: \\n\", classification_report(y_test, y_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x27b93fb8788>"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_test[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnn.save('models')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading images ...\n",
      "[INFO] Image loading completed\n"
     ]
    }
   ],
   "source": [
    "\n",
    "basepath = r'C:\\projects\\digit_prediction\\vision_verse\\data\\test'\n",
    "timage_list, tlabel_list = [], []\n",
    "\n",
    "print(\"[INFO] Loading images ...\")\n",
    "root_dir = listdir(basepath)\n",
    "\n",
    "for images in root_dir:\n",
    "    image_directory = os.path.join(basepath,images)\n",
    "    timage_list.append(convert_image_to_array(image_directory))\n",
    "print(\"[INFO] Image loading completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1101"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(timage_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "timage_list = np.array(timage_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = cnn.predict(timage_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "yclasses = [np.argmax(element) for element in preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "classes = label_binarizer.inverse_transform(yclasses)\n",
    "sub = pd.DataFrame(data={\n",
    "    'path':os.listdir(basepath),\n",
    "    'label':classes\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000.jpg</td>\n",
       "      <td>crownandrootrot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0001.jpg</td>\n",
       "      <td>crownandrootrot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00010.jpg</td>\n",
       "      <td>crownandrootrot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000100.jpg</td>\n",
       "      <td>crownandrootrot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001000.jpg</td>\n",
       "      <td>wheatloosesmut</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          path            label\n",
       "0     0000.jpg  crownandrootrot\n",
       "1     0001.jpg  crownandrootrot\n",
       "2    00010.jpg  crownandrootrot\n",
       "3   000100.jpg  crownandrootrot\n",
       "4  0001000.jpg   wheatloosesmut"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub['path'] = sub['path'].apply(lambda x: f\"data/test/{x}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/test/0000.jpg</td>\n",
       "      <td>crownandrootrot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/test/0001.jpg</td>\n",
       "      <td>crownandrootrot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/test/00010.jpg</td>\n",
       "      <td>crownandrootrot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/test/000100.jpg</td>\n",
       "      <td>crownandrootrot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/test/0001000.jpg</td>\n",
       "      <td>wheatloosesmut</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    path            label\n",
       "0     data/test/0000.jpg  crownandrootrot\n",
       "1     data/test/0001.jpg  crownandrootrot\n",
       "2    data/test/00010.jpg  crownandrootrot\n",
       "3   data/test/000100.jpg  crownandrootrot\n",
       "4  data/test/0001000.jpg   wheatloosesmut"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv(r'C:\\projects\\digit_prediction\\vision_verse\\submissions\\sub10.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "leafrust           304\n",
       "healthywheat       289\n",
       "crownandrootrot    274\n",
       "wheatloosesmut     234\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f863957d7900215f0188833c8951c85aa5ce4efd5a05e0f4333c2cff58019422"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
